{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convolutional variational autoencoder\n",
    "- generate a bunch of new ones\n",
    "- interpolate between emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Layer as KerasLayer\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VariationalLayer(KerasLayer):\n",
    "\n",
    "    def __init__(self, output_dim: int, epsilon_std=1.):\n",
    "        '''A custom \"variational\" Keras layer that completes the\n",
    "        variational autoencoder.\n",
    "\n",
    "        Args:\n",
    "            output_dim : The desired number of latent dimensions in our\n",
    "                embedding space.\n",
    "        '''\n",
    "        self.output_dim = output_dim\n",
    "        self.epsilon_std = epsilon_std\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.z_mean_weights = self.add_weight(\n",
    "            shape=(input_shape[1], self.output_dim),\n",
    "            initializer='glorot_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.z_mean_bias = self.add_weight(\n",
    "            shape=(self.output_dim,),\n",
    "            initializer='zero',\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.z_log_var_weights = self.add_weight(\n",
    "            shape=(input_shape[1], self.output_dim),\n",
    "            initializer='glorot_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.z_log_var_bias = self.add_weight(\n",
    "            shape=(self.output_dim,),\n",
    "            initializer='zero',\n",
    "            trainable=True\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        z_mean = K.dot(x, self.z_mean_weights) + self.z_mean_bias\n",
    "        z_log_var = K.dot(x, self.z_log_var_weights) + self.z_log_var_bias\n",
    "        epsilon = K.random_normal(\n",
    "            shape=K.shape(z_log_var),\n",
    "            mean=0.,\n",
    "            stddev=self.epsilon_std\n",
    "        )\n",
    "\n",
    "        kl_loss_numerator = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "        self.kl_loss = -0.5 * K.sum(kl_loss_numerator, axis=-1)\n",
    "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "    def loss(self, x, x_decoded):\n",
    "        return mean_squared_error(x, x_decoded) + self.kl_loss\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VariationalAutoEncoderEmbeddingModel(BaseEmbeddingModel):\n",
    "    \n",
    "    def __init__(self, embedding_size: int, dense_layer_size: int, λ: float):\n",
    "        '''Initializes the model parameters.\n",
    "        \n",
    "        Args:\n",
    "            embedding_size : The desired number of latent dimensions in our \n",
    "                embedding space.\n",
    "            λ : The regularization strength to apply to the model's\n",
    "                dense layers.\n",
    "        '''\n",
    "        self.embedding_size = embedding_size\n",
    "        self.dense_layer_size = dense_layer_size\n",
    "        self.λ = λ\n",
    "        self.n_unique_airports = n_unique_airports\n",
    "        self.variational_layer = VariationalLayer(embedding_size)\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        # encoder\n",
    "        origin = Input(shape=(self.n_unique_airports,), name='origin')\n",
    "        origin_geo = Input(shape=(2,), name='origin_geo')\n",
    "        dense = concatenate([origin, origin_geo])\n",
    "        dense = Dense(self.dense_layer_size, activation='tanh', kernel_regularizer=l2(self.λ))(dense)\n",
    "        dense = BatchNormalization()(dense)\n",
    "        variational_output = self.variational_layer(dense)\n",
    "\n",
    "        encoder = Model([origin, origin_geo], variational_output, name='encoder')\n",
    "\n",
    "        # decoder\n",
    "        latent_vars = Input(shape=(self.embedding_size,))\n",
    "        dense = Dense(self.dense_layer_size, activation='tanh', kernel_regularizer=l2(self.λ))(latent_vars)\n",
    "        dense = Dense(self.dense_layer_size, activation='tanh', kernel_regularizer=l2(self.λ))(dense)\n",
    "        dense = BatchNormalization()(dense)\n",
    "        dest = Dense(self.n_unique_airports, activation='softmax', name='dest', kernel_regularizer=l2(self.λ))(dense)\n",
    "        dest_geo = Dense(2, activation='linear', name='dest_geo')(dense)\n",
    "\n",
    "        decoder = Model(latent_vars, [dest, dest_geo], name='decoder')\n",
    "\n",
    "        # end-to-end\n",
    "        encoder_decoder = Model([origin, origin_geo], decoder(encoder([origin, origin_geo])))\n",
    "        return encoder_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae_model = VariationalAutoEncoderEmbeddingModel(embedding_size=1, dense_layer_size=20, λ=.003)\n",
    "vae_model.compile(optimizer=Adam(lr=LEARNING_RATE), loss=[vae_model.variational_layer.loss, 'mean_squared_logarithmic_error'], \n",
    "                  loss_weights=[1., .2])\n",
    "SVG(model_to_dot(vae_model.model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question-answer models for emoji responses\n",
    "- when predicting, you can predict onto the generated emojis as well!\n",
    "- add some dropout\n",
    "- vanishing/exploding gradients\n",
    "- spaCy for word2vec embeddings?\n",
    "\n",
    "## bi-directional lstms\n",
    "- \"Bidirectional Long Short-Term Memory (biLSTM): Single direction LSTMs suffer a weakness\n",
    "of not utilizing the contextual information from the future tokens. Bidirectional LSTM utilizes both\n",
    "the previous and future context by processing the sequence on two directions, and generate two\n",
    "independent sequences of LSTM output vectors. One processes the input sequence in the forward\n",
    "direction, while the other processes the input in the reverse direction. The output at each time step\n",
    "is the concatenation of the two output vectors from both directions, ie. ht =\n",
    "−→ht k\n",
    "←−ht .\" (https://arxiv.org/pdf/1511.04108.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# references\n",
    "- http://ben.bolte.cc/blog/2016/language.html\n",
    "- https://arxiv.org/pdf/1508.01585v2.pdf\n",
    "- https://arxiv.org/pdf/1511.04108.pdf\n",
    "- https://explosion.ai/blog/deep-learning-formula-nlp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
